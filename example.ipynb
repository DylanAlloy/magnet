{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíª set up your environment\n",
    "\n",
    "###### your source data should a csv/json path or a dataframe and contain **at least** one column with plaintext\n",
    "\n",
    "###### ‚ö°Ô∏è assuming for each transformation that you have the step-wise data ready to go, this block is all you need to initialize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magnet.processing import Processor\n",
    "source_data_file = \"./raw/knowledge_base_export.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìë create sentences from plaintext\n",
    "###### we set an output filename, an input directory, and an output directory with our `Processor` class\n",
    "\n",
    "###### then we load the specific raw data file into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_sentence_proc = Processor()\n",
    "kb_sentence_proc.load(source_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ü•≥ great! let's process our data, _fast_\n",
    "\n",
    "##### ‚ö°Ô∏è first we extract sentences for our embedding model to get initial scores and examples from\n",
    "\n",
    "###### don't forget to declare your plaintext column's name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_sentence_proc.export_as_sentences('./data/sentences.parquet','clean','answerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßÆ indexing data \n",
    "\n",
    "in `magnet`, we have different submodules responsible for different parts of building our \"data field\" of vectors.\n",
    "\n",
    "import `charge` to create a \"Pole\" and index your sentences to it using your embedding model.\n",
    "you can think of the vectors as electrons which belong to charged particles in a magnetic pole, or you can ignore the metaphor completely!\n",
    "\n",
    "then we save our embeddings to re-use later and upload/share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magnet.ize import charge\n",
    "charge = charge.Pole()\n",
    "charge.index_document_embeddings(df=kb_sentence_proc.df)\n",
    "charge.save_embeddings('./data/sentence_embeddings.index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üìä now let's score our sentences against those found in random batches of documents!\n",
    "\n",
    "###### üìñ 1Ô∏è‚É£ `split` by default is 16 which uses said fraction of your data to create examples from.\n",
    "\n",
    "###### üìñ 2Ô∏è‚É£ we then create a subsampling of our newly scored data. this is a requirement for sorting positive and negative samples later when we export finetuning datasets. \n",
    "\n",
    "###### we're going to use `FinePrep` class to prepare our data for finetuning training runs\n",
    "\n",
    "###### don't forget to declare your `group_by` column in `generate_scored_data` as well as the name of the original plaintext column so we can persist it across datasets\n",
    "\n",
    "###### **‚ú® this scoring can be done with any `sentence-transformers` model you like, not necessarily the one you are finetuning (`model=''`)! you can also insert a custom** `prompt` **if the model benefits from it ‚ú®**\n",
    "\n",
    "###### (for example, when using `bge-large-en-v1.5` for `retrieval` instead of `similarity` tuning, a prompt is required)\n",
    "\n",
    "###### üö® `generate_scored_data` can take some time if `use_multiprocessing` is not enabled, and using it is compute-intensive\n",
    "\n",
    "###### ‚ÑπÔ∏è multiprocessing is not needed if you are using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from magnet.finetune import FinePrep\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('./data/sentences.parquet')\n",
    "sentences_data_file = 'sentences.parquet'\n",
    "task = 'similarity'\n",
    "kb_prepper = FinePrep()\n",
    "kb_prepper.load(os.path.join('./data/',sentences_data_file))\n",
    "kb_prepper.generate_training_data(out_dir='./data/',k=64, index='./data/sentence_embeddings.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils().upload_to_s3(\n",
    "#     './data/fn_hn_kb.jsonl'\n",
    "#     , ('AWS_CLIENT_KEY', 'AWS_SECRET_KEY')\n",
    "#     , 'bucket_name'\n",
    "#     , 'finetuning_data'\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
